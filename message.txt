Populate the interview summary to this format Candidate Summary – First Interview Assessment Candidate Information: Name: [Full Name] Position Applied For: [Job Title] Location: [City, Country] Email: [Email Address] Contact Number: [Phone Number] Education: [Course, Year Graduated, School] 1. Work Experience Overview: Total Years in Industry: [X years] Has worked with clients from [regions: e.g., US, Canada, Singapore, AU] Certifications: [Any additional certifications, side projects, or self-learning efforts] Recent Companies & Key Responsibilities: [Company 1] – [Short summary of role] [Company 2] – [Short summary of role] 2. Technical Skills & Competencies: Skill/Tool - Years of Experience [Tool/Tech] - [# yrs] (Proficiency]) 3. Work Preferences & Availability: Amenability to Remote Work Setup: [Yes/No] Own Equipment & Internet: [Yes/No] Availability to Start: [e.g., ASAP/ 30 days notice] 4. Salary Information: Previous/Current Salary: [e.g., PHP 90K] Expected Salary: [e.g., PHP 100K] Employment Type: [Contractor / FTE] 5. Reason(s) for Leaving Previous Roles: [Company 1] – [Reason] [Company 2] – [Reason] 6. Red Flags or Concerns (if any): [e.g., Gap in employment, inconsistent roles, unclear experience with specific tools] [If none, write “None”] 7. Interviewer Assessment Summary: Category Rating (1–5) Communication Technical Fit Culture Fit Overall Recommendation ------------------------------------------------------
### **Candidate Information**

**Name: Athena**

**Position:**

**Location:**

**Email:**

**Contact #:**

---

### **First Interview Script**

Hi, ________. Thank you for joining this call. My name is Ciceley, I’m part of the technical recruitment team. How would you like me to address you?

This is a screening call where I will have a couple of questions regarding your work experience, technical skills, and how your skills align with the role. Should you pass this pre-screening call, you will have 2 more rounds of interviews.

Before we proceed, let me give you a brief walkthrough about Adaca:

Adaca is an IT services and consulting company based in Sydney, Australia.

Basically, we partner with companies in Australia, and we serve as the direct employer of employees here in the Philippines. Our Philippine-based team collaborates with our clients across different industries to deliver IT solutions and services.

Since we have a PH entity, if you are hired you will receive:

- HMO
- Government-mandated benefits
- 13th month pay
- 15 days paid time off
- Certifications via Udemy

Alternatively, we also provide an Independent Contractor arrangement for those who prefer not to receive government-mandated benefits. Under this arrangement, there will be no HMO coverage or government benefit deductions.

**Work setup:** Permanent remote, AU working hours (6AM–3PM / 7AM–4PM / 8AM–5PM / 9AM–6PM)

Are you comfortable with these hours?- Yes

---

### **Interview Questions**

**Employment Status:**

Are you currently employed?- No, finished contract last december 2025

Any part-time or freelance work?: none 

Availability to start: ASAP

**Salary Questions:**

- Current salary: 100k
- Does your current compensation package include additional benefits? (non-taxable allowance)?- yes
- Expected salary: 100k Independent Contractor

---

### **Work Experience**

- Total years of experience: 6 years (6 years- data analyst)
- Experience with international clients (Which nationalities?):US, UK, Australian
- Team management experience (How many?): before. hybrid role- she was asked to train new hires data analyst and engineer, 2 people only
- Certifications acquired: data camp and udemy

---

### **Technical Questions / Tech Stack**

1. **SQL Proficiency**
    
    *Describe a complex SQL query you’ve written recently. What joins, aggregations, or optimisations did you use?-* 
    
    For SQL, the complex one I've made is in the Australian company that I've worked with. I'm actually working with the fraud team, so most of their rules are. Translated into SQL so they have to let me know what requirements are needed and the logic behind the the rules and then I have to translate it in SQL so that it would be automated on their end when alerts are needed.  And then for the joints mostly either. Left join or right join. It's not we we we rarely use full join since it takes a lot of time and storage as well. In the same life, the the most complex one that we've made is the is I. Combining a lot of different sources into one dashboard. We mainly use Snowflake for that, so you have to ingest different sources into Snowflake and then translate it into Power BI. For the snowflake it's it's mainly SQL, so different CTES, different logic per table, different views, and then you have to connect it to just one thing with.  With actually thinking about the performance, whether it's gonna be too slow or too fast, too slow because having a fast ingest in. Fast running of the SQL code is actually good, especially when you have to put it in a Power BI dashboard.
    
2. **dbt Experience**
    
    *What types of dbt models have you built, and how do you typically structure staging vs mart models? - Yes, in the Australian company they mainly use DBT. We have to use GitHub for that and then create test scripts in it before we have to deploy to the. The main the the prod.* For DBT when we're usually it's per ticket when creating. Uh model and so that uh we were we could easily track which one would um. Collide with the current, the current prod data. So that's what we usually do and then before we deploy to prod. We have to um. Have series of checks with the team to check if the output is what we are expecting and then we have to deploy to prod and then test again if there are any problems.
    
3. **Snowflake Expertise**
    
    *How do you optimise query performance and manage costs in Snowflake?-* Um, in Snowflake we actually have to always manage our costs. Since in Singlife they have limited credits per month. So for that we have to check the daily credits each query um gets and then we have to. Forecast weather certain times that a certain query needs to be run again. We have to take that in the take that in mind in the forecast since even. Big queries actually take like around 100 credits for like one run and sometimes it's well for those kind of kinds of queries, we don't run it monthly, maybe around quarterly, but. It has to be put into consideration when you're, um, doing your forecasting credits, and then when we do our queries there, mostly we. Well, me for for me, I use CTES and then mostly temporary tables just to, uh, lessen the credit. The credits used and then before before creating a new view for it.
    
4. **Reporting & Dashboards (ThoughtSpot)**
    
    *Do you have experience building dashboards in ThoughtSpot? How about any tool similar to ThoughtSpot? - tablaeu, powerbi, looker.* For the previous the Australian company, they mainly use Looker and Tableau for their dashboards and forcing life it's mainly Power BI and then the previous ones in. Like invested as a BI data engineer, we mainly use just Python in creating our dashboard since what we do there is Mini softwares that we could deploy on certain stakeholders. Um. Device and then it would generate the graphs there and then. Mostly Power BI, Tableau and looker
    
5. **Security & Compliance Awareness**
    
    *How do you handle sensitive data and ensure compliance with security or HIPAA-related requirements in analytics workflows?- During my time in Singlife, we were actually asked to have certifications with the data security in because the law, the legal team requires us to do that.* So that if ever there's a leakage, we wouldn't. We'd be able to trace it back from where it came from, so.For that, we were actually very, um. OK, go on that. Um. Like like when transferring certain data to others, especially when dashboards contain personal informations, we have to. Check each and every stakeholder that would use that dashboard and then they have to get back to us if they want an access to it and then they have to provide the a reason why we would like we should provide it and then ask the legal team to. For the confirmation that they would that they should be given the access to it. So that's our process. It's not only it's not our say all the time, it's from the legal team and then back to us and then we will give the access.
    
- Relevant tools and technologies used:

Core technical skills:

- Advanced SQL: 6 yrs
- Dbt: 1 year, git: 3-4 yrs, databricks: 1 yr
- Snowflake: 3-4 yrs, Metabase: 2 yrs
- Snowflake schema design: 3-4 yrs
- Thoughtspot dashboard: used Tableau: 2 yrs, PowerBI: 4 yrs, Looker: 2-3 yrs

Data Quality and Analytics:

- data validation and accuracy checks: 6 yrs
- data modelling for analytics and reporting: 4-5 yrs
- translating business questions into actionable data insights: 6 yrs, brd creation, stakeholder management

Security and compliance:

- experience working with HIPAA or other regulated data environments: 6 yrs
- awareness of cybersecurity and data governance practices: 6 yrs
- adherence to data access controls and security policies: 6 yrs

---

### **Reasons for Leaving Previous Roles**

Confidential- part-time

Confidential- contract-based

singlife ph- rto 5x a week and her home is far from the office
InvestED PH- the data team was removed because they no longer need

Boldr Inc.- the work got repetitive, she automated a lot and as a data analyst- need to be updated with technologies and upskilling, she needed a change of environment to grow her skill

---

### **Notes / Key Strengths**

---

### **To End the Interview**

- Location: Bacoor Cavite
- Own equipment (yes/no): yes
- Internet speed: 100 mbps
- Education (School, Course, Year):
- Other job applications? Status?- yes actively looking